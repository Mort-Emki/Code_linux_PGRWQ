#!/usr/bin/env python3
"""
check_binary_compatibility.py - æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºäºŒè¿›åˆ¶å…¼å®¹æ ¼å¼

ç”¨äºéªŒè¯ç°æœ‰æ•°æ®æ˜¯å¦å·²è½¬æ¢ä¸ºé«˜æ•ˆæµé‡è®¡ç®—æ‰€éœ€çš„äºŒè¿›åˆ¶æ ¼å¼
"""

import os
import pandas as pd
import logging
from pathlib import Path

def check_data_compatibility(data_path: str) -> dict:
    """
    æ£€æŸ¥æ•°æ®æ˜¯å¦å…¼å®¹æ–°çš„é«˜æ•ˆæµé‡è®¡ç®—ç³»ç»Ÿ
    
    å‚æ•°:
        data_path: æ•°æ®æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
        
    è¿”å›:
        æ£€æŸ¥ç»“æœå­—å…¸
    """
    result = {
        'compatible': False,
        'format': 'unknown',
        'issues': [],
        'recommendations': []
    }
    
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
        if os.path.isfile(data_path):
            if data_path.endswith('.csv'):
                result['format'] = 'csv'
                result['issues'].append('CSVæ ¼å¼ä¸æ”¯æŒé«˜æ•ˆè®¡ç®—')
                result['recommendations'].append('è¯·ä½¿ç”¨scripts/csv_to_binary_converter.pyè½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ¼å¼')
                
            elif data_path.endswith(('.npz', '.npy')):
                result['format'] = 'numpy'
                result['issues'].append('éœ€è¦æ£€æŸ¥æ˜¯å¦ç¬¦åˆEfficientDataLoaderæ ¼å¼è¦æ±‚')
                result['recommendations'].append('ç¡®è®¤æ•°æ®ç»“æ„åŒ…å«ï¼šdata.npy, dates.npy, metadata.json')
                
        # æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
        elif os.path.isdir(data_path):
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„äºŒè¿›åˆ¶æ•°æ®ç›®å½•
            required_files = ['metadata.json', 'data.npy', 'dates.npy']
            missing_files = []
            
            for file_name in required_files:
                file_path = os.path.join(data_path, file_name)
                if not os.path.exists(file_path):
                    missing_files.append(file_name)
            
            if not missing_files:
                # éªŒè¯å…ƒæ•°æ®æ ¼å¼
                import json
                metadata_path = os.path.join(data_path, 'metadata.json')
                
                try:
                    with open(metadata_path, 'r') as f:
                        metadata = json.load(f)
                    
                    required_fields = ['n_comids', 'n_days', 'feature_columns', 'comid_list']
                    missing_fields = [f for f in required_fields if f not in metadata]
                    
                    if not missing_fields:
                        result['compatible'] = True
                        result['format'] = 'efficient_binary'
                        
                        # é¢å¤–ä¿¡æ¯
                        result['stats'] = {
                            'n_comids': metadata['n_comids'],
                            'n_days': metadata['n_days'],
                            'features': metadata['feature_columns'],
                            'estimated_memory_saving': 'çº¦400xå†…å­˜å‡å°‘'
                        }
                    else:
                        result['issues'].extend([f'å…ƒæ•°æ®ç¼ºå°‘å­—æ®µ: {field}' for field in missing_fields])
                        
                except Exception as e:
                    result['issues'].append(f'å…ƒæ•°æ®è¯»å–å¤±è´¥: {e}')
            else:
                result['format'] = 'incomplete_binary'
                result['issues'].extend([f'ç¼ºå°‘å¿…è¦æ–‡ä»¶: {file}' for file in missing_files])
                result['recommendations'].append('ä½¿ç”¨csv_to_binary_converter.pyé‡æ–°è½¬æ¢æ•°æ®')
                
        else:
            result['issues'].append(f'è·¯å¾„ä¸å­˜åœ¨: {data_path}')
            
    except Exception as e:
        result['issues'].append(f'æ£€æŸ¥è¿‡ç¨‹å‡ºé”™: {e}')
        
    return result


def print_compatibility_report(data_path: str):
    """
    æ‰“å°æ•°æ®å…¼å®¹æ€§æŠ¥å‘Š
    
    å‚æ•°:
        data_path: æ•°æ®è·¯å¾„
    """
    print(f"\n=== æ•°æ®å…¼å®¹æ€§æ£€æŸ¥æŠ¥å‘Š ===")
    print(f"æ£€æŸ¥è·¯å¾„: {data_path}")
    print(f"æ£€æŸ¥æ—¶é—´: {pd.Timestamp.now()}")
    
    result = check_data_compatibility(data_path)
    
    print(f"\næ ¼å¼ç±»å‹: {result['format']}")
    print(f"å…¼å®¹æ€§: {'âœ… å…¼å®¹' if result['compatible'] else 'âŒ ä¸å…¼å®¹'}")
    
    if result['compatible']:
        print(f"\nâœ… æ­å–œï¼æ‚¨çš„æ•°æ®å·²ç»æ˜¯é«˜æ•ˆäºŒè¿›åˆ¶æ ¼å¼")
        if 'stats' in result:
            stats = result['stats']
            print(f"   - COMIDæ•°é‡: {stats['n_comids']:,}")
            print(f"   - æ—¶é—´å¤©æ•°: {stats['n_days']:,}")
            print(f"   - ç‰¹å¾æ•°é‡: {len(stats['features'])}")
            print(f"   - å†…å­˜ä¼˜åŒ–: {stats['estimated_memory_saving']}")
            print(f"   - ç‰¹å¾åˆ—è¡¨: {', '.join(stats['features'][:5])}{'...' if len(stats['features']) > 5 else ''}")
    else:
        print(f"\nâŒ å‘ç°é—®é¢˜:")
        for issue in result['issues']:
            print(f"   - {issue}")
            
        print(f"\nğŸ’¡ å»ºè®®:")
        for rec in result['recommendations']:
            print(f"   - {rec}")
        
        if result['format'] == 'csv':
            print(f"\nğŸš€ è½¬æ¢å‘½ä»¤:")
            print(f"   python scripts/csv_to_binary_converter.py --input {data_path} --output {data_path.replace('.csv', '_binary')}")
    
    print("\n" + "="*50)


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ£€æŸ¥æ•°æ®æ ¼å¼å…¼å®¹æ€§')
    parser.add_argument('data_path', help='æ•°æ®æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œåªè¿”å›ç»“æœ')
    
    args = parser.parse_args()
    
    if args.quiet:
        result = check_data_compatibility(args.data_path)
        exit(0 if result['compatible'] else 1)
    else:
        print_compatibility_report(args.data_path)


if __name__ == '__main__':
    main()